{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DVS_Gesture.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7t_qlnTVWWS"
      },
      "source": [
        "!pip install snntorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpJrTa3XVaSQ"
      },
      "source": [
        "import snntorch as snn\n",
        "from snntorch.spikevision import spikedata \n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7kYJ5reVeDA"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbHJ827iVcYY"
      },
      "source": [
        "# note that a default transform is already applied to keep things easy\n",
        "\n",
        "dvs_train = spikedata.DVSGesture(\"data/dvsgesture\", train=True, dt=1000, num_steps=500, ds=1)  # ds: spatial compression; dt: temporal compressiondvs_test\n",
        "dvs_test = spikedata.DVSGesture(\"data/dvsgesture\", train=False, dt=1000, num_steps=1800, ds=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "AWQTG9lhVmKY",
        "outputId": "3d607d3e-b416-4a47-e61e-4d562ed52dba"
      },
      "source": [
        "dvs_test"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1b6453ff6f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdvs_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dvs_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buI7BN_JVvSb"
      },
      "source": [
        "## DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWhGAeVLVws5"
      },
      "source": [
        "dvs_train_dl = DataLoader(dvs_train, shuffle=True, batch_size=64)\n",
        "dvs_test_dl = DataLoader(dvs_test, shuffle=False, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhwnXKs_VxgZ"
      },
      "source": [
        "# get a feel for the data\n",
        "dvs_train_dl.dataset[0][0].size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8mEmv8PV9qK"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTt_4BlqV3vP"
      },
      "source": [
        "n = 3  # random index into a sample\n",
        "\n",
        "# flatten on-spikes and off-spikes into one channel\n",
        "a = (dvs_train_dl.dataset[n][0][:, 0] + dvs_train_dl.dataset[n][0][:, 1])\n",
        "print(f\"in case you're blind AF, the target is: {spikedata.dvs_gesture.mapping[dvs_train_dl.dataset[n][1]]}\")\n",
        "\n",
        "#  Plot\n",
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(a, fig, ax, interval=10)\n",
        "HTML(anim.to_html5_video())\n",
        "\n",
        "# anim.save('nmnist_animation.mp4', writer = 'ffmpeg', fps=50)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDDqdJ1YWBns"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpiRF7pqV9AJ"
      },
      "source": [
        "plt.imshow(torch.sum(dvs_train_dl.dataset[4][0][:300,0,:,:], axis=0), cmap='hot')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gZariHNWH-X"
      },
      "source": [
        "spikedata.dvs_gesture.mapping"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}