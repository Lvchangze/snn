{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "glove_path = \"data/glove.6B.100d.txt\"\n",
    "bias = 3\n",
    "glove_dict = {}\n",
    "with open(glove_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        glove_dict[word] = vector\n",
    "# print(len(glove_dict))\n",
    "# print(glove_dict.keys())\n",
    "print(glove_dict['recent'].shape[-1])\n",
    "mean_value = np.mean(list(glove_dict.values()))\n",
    "vairance_value = np.var(list(glove_dict.values()))\n",
    "left = mean_value - vairance_value * bias\n",
    "right = mean_value + vairance_value * bias\n",
    "for key in glove_dict.keys():\n",
    "    temp_clip = np.clip(glove_dict[key], left, right)\n",
    "    temp = (temp_clip - mean_value) / (bias * vairance_value)\n",
    "    glove_dict[key] = temp + 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujh/miniconda3/envs/snn/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModuleList(\n",
      "  (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
      "  (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
      "  (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
      "), ModuleList(\n",
      "  (0): MaxPool2d(kernel_size=(23, 1), stride=(23, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (1): MaxPool2d(kernel_size=(22, 1), stride=(22, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (2): MaxPool2d(kernel_size=(21, 1), stride=(21, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "), Leaky(), Linear(in_features=300, out_features=2, bias=True), Leaky()]\n"
     ]
    }
   ],
   "source": [
    "from args import SNNArgs\n",
    "from model.textcnn import TextCNN\n",
    "from main import *\n",
    "from snntorch import surrogate\n",
    "\n",
    "arg = SNNArgs()\n",
    "build_environment(arg)\n",
    "model = TextCNN(arg, spike_grad=surrogate.fast_sigmoid).to(arg.device)\n",
    "\n",
    "print(list(model._modules.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False, False, False, False,  True])\n",
      "tensor(2)\n",
      "3.5\n",
      "spike no.0: dead ratio0, spike no.1: dead ratio2, spike no.2: dead ratio3, spike no.3: dead ratio4, spike no.4: dead ratio5\n"
     ]
    }
   ],
   "source": [
    "# for c in model.convs_1:\n",
    "#     print(c)\n",
    "spikes = torch.tensor([0,1,1,1,1,1,0])\n",
    "zeros = torch.eq(spikes, 0)\n",
    "print(zeros)\n",
    "print(torch.sum(zeros))\n",
    "# print(zeros.shape[0].item())\n",
    "print(7/2)\n",
    "l = [0,2,3,4,5]\n",
    "print(\", \".join([\"spike no.{}: dead ratio:{}\".format(index, value) \n",
    "            for index, value in enumerate(l)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 2]\n",
      " [3 0]\n",
      " [2 0]\n",
      " [0 1]], shape=(4, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3]\n",
      " [3]\n",
      " [2]\n",
      " [0]], shape=(4, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3 2]\n",
      " [3 0]\n",
      " [2 0]\n",
      " [0 1]], shape=(4, 2), dtype=int32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run() missing 1 required positional argument: 'fetches'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/xujh/snn/zz.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.176.56.53/home/xujh/snn/zz.ipynb#ch0000003vscode-remote?line=7'>8</a>\u001b[0m top_2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mslice(indices, [\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m], [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.176.56.53/home/xujh/snn/zz.ipynb#ch0000003vscode-remote?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(top_2)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.176.56.53/home/xujh/snn/zz.ipynb#ch0000003vscode-remote?line=9'>10</a>\u001b[0m sess\u001b[39m.\u001b[39;49mrun()\n",
      "\u001b[0;31mTypeError\u001b[0m: run() missing 1 required positional argument: 'fetches'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.compat.v1.Session()\n",
    "x = tf.constant([[1,2,3,4], [4,3,2,5],[6,3,7,1], [8,6,4,1]])\n",
    "_, indices = tf.nn.top_k(x, k=2, sorted=True)\n",
    "print(indices)\n",
    "top_1 = tf.slice(indices, [0,0], [-1,1])\n",
    "print(top_1)\n",
    "top_2 = tf.slice(indices, [0,0], [-1,2])\n",
    "print(top_2)\n",
    "sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xujh/miniconda3/envs/snn/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "def permu(bit, dep, a, ret):\n",
    "    if (dep == bit):\n",
    "        ret.append(copy.deepcopy(a))\n",
    "        return\n",
    "    a[dep] = 1\n",
    "    permu(bit, dep+1, a, ret)\n",
    "    a[dep] = 0\n",
    "    permu(bit, dep+1, a, ret)\n",
    "\n",
    "def green(bit, dep, res, a, ret):\n",
    "    if (res == 0):\n",
    "        ret.append(copy.deepcopy(a))\n",
    "        return\n",
    "    for i in range(bit-res, dep-1, -1):\n",
    "        a[i] = 0\n",
    "        green(bit, i+1, res-1, a, ret)\n",
    "        a[i] = 1\n",
    "\n",
    "def preprocess(bit=8):\n",
    "    a = [0 for _ in range(bit)]\n",
    "    permu_a, greencode = [], []\n",
    "    permu(bit, 0, a, permu_a)\n",
    "    a = [1 for _ in range(bit)]\n",
    "    for num0 in range(bit+1):\n",
    "        green(bit, 0, num0, a, greencode)\n",
    "    greencode = greencode[::-1]\n",
    "    return permu_a, greencode\n",
    "\n",
    "def encode(x, codebook, step_num=32, bit=8):\n",
    "    bin_num = 1 << bit\n",
    "    stride = 1. / bin_num\n",
    "    bin_idx = min(int(x / stride), bin_num-1)\n",
    "    spike = codebook[bin_idx]\n",
    "    return int(step_num / bit) * spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 1, 1], [0, 1, 0, 1], [0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 1, 0, 0], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0], [1, 1, 1, 1]]\n",
      "[[1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 0, 0], [1, 0, 1, 1], [1, 0, 1, 0], [1, 0, 0, 1], [1, 0, 0, 0], [0, 1, 1, 1], [0, 1, 1, 0], [0, 1, 0, 1], [0, 1, 0, 0], [0, 0, 1, 1], [0, 0, 1, 0], [0, 0, 0, 1], [0, 0, 0, 0]]\n",
      "torch.Size([16, 4])\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=torch.int32)\n",
      "torch.Size([100, 4])\n",
      "[1, 2]\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "bit = 4\n",
    "p_a, greencode = preprocess(bit=bit)\n",
    "print(greencode)\n",
    "print(p_a)\n",
    "torch_green = torch.tensor(greencode, dtype=torch.float)\n",
    "print(torch_green.shape)\n",
    "bin_num = 1 << bit\n",
    "stride = 1. / bin_num\n",
    "temp = []\n",
    "for i in range(10):\n",
    "    temp += [i/10 for _ in range(10)]\n",
    "x = torch.tensor(temp)\n",
    "bin_idx = torch.clamp(torch.floor(x / stride), max=bin_num-1).int()\n",
    "print(bin_idx)\n",
    "y = torch.index_select(torch_green, 0, bin_idx)\n",
    "print(y.shape)\n",
    "temp_shape = [1 for _ in range(len(y.shape))]\n",
    "temp_shape[-1] = 2\n",
    "print(temp_shape)\n",
    "print(y.repeat(temp_shape))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1260dce2d3a11cccd94bfdf34d82d88f5153cc919d8397f861b831affa4820d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
